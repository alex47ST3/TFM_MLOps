{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer\n",
    "import classes.utils as utils\n",
    "from classes.splitter import Splitter\n",
    "\n",
    "\n",
    "utils.set_parent_directory_as_working_directory()\n",
    "\n",
    "# TODO: Move this to a config file\n",
    "# Importing\n",
    "DATA_FOLDER = \"./data\"\n",
    "\n",
    "\n",
    "FE_DATA_PATH = DATA_FOLDER +'/fe_data.csv'\n",
    "DATES_DATA_PATH = DATA_FOLDER +'/dates_data.csv'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Introduction\n",
    "In this notebook we will develop our first model. We are going to assume that we have 1 year of loans that have finished (finished_d = issued date + total length of loan), which basically place ourselves on 2011-05-01.\n",
    "\n",
    "\n",
    "# 1 Splitting data\n",
    "Before we get hands on with the modelling, we need to split the data into train and test sets. As we mentioned in the preprocessing notebook we will be using the create variable  'finished_d' to \n",
    "\n",
    "We will use the train set to train the model and the test set to evaluate the model. We will use the train_test_split function from sklearn to split the data. We will use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ./data/fe_data.csv\n",
      "Dates data loaded from ./data/dates_data.csv\n",
      "Date column finished_d added to the data\n"
     ]
    }
   ],
   "source": [
    "splitter_name = \"splitter\"\n",
    "\n",
    "splitter = Splitter(\n",
    "    name = splitter_name\n",
    "    , data_path = FE_DATA_PATH\n",
    "    , date_cols = []\n",
    "    , target_variable = 'loan_status'\n",
    "    , destination_directory = DATA_FOLDER\n",
    "    , dates_data_path = DATES_DATA_PATH\n",
    "    , column_to_split_by = 'finished_d'\n",
    "    , number_of_months = 12\n",
    "    , test_size = 0.3\n",
    "    , random_state = 47\n",
    ")\n",
    "\n",
    "splitter.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test and train attributes defined 0.3.\n",
      "        Test size: 597\n",
      "        Train size: 1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\TFM\\TFM_MLOps\\mlflow_project\\src\\classes\\splitter.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.drop(columns=self.column_to_split_by, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "splitter.split_data_filtered(number_of_months=12)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
