{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer\n",
    "import classes.utils as utils\n",
    "from classes.splitter import Splitter\n",
    "\n",
    "\n",
    "utils.set_parent_directory_as_working_directory()\n",
    "\n",
    "# TODO: Move this to a config file\n",
    "# Importing\n",
    "DATA_FOLDER = \"./data\"\n",
    "\n",
    "\n",
    "FE_DATA_PATH = DATA_FOLDER +'/fe_data.csv'\n",
    "DATES_DATA_PATH = DATA_FOLDER +'/dates_data.csv'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Introduction\n",
    "In this notebook we will develop our first model. We are going to assume that we have 1 year of loans that have finished (finished_d = issued date + total length of loan), which basically place ourselves on 2011-05-01.\n",
    "\n",
    "\n",
    "# 1 Splitting data\n",
    "Before we get hands on with the modelling, we need to split the data into train and test sets. As we mentioned in the preprocessing notebook we will be using the create variable  'finished_d' to \n",
    "\n",
    "We will use the train set to train the model and the test set to evaluate the model. We will use the train_test_split function from sklearn to split the data. We will use 80% of the data for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ./data/fe_data.csv\n",
      "Dates data loaded from ./data/dates_data.csv\n",
      "Date column finished_d added to the data\n",
      "Data filtered by 12 months\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Desktop\\TFM\\TFM_MLOps\\mlflow_project\\src\\classes\\splitter.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data.drop(columns=self.column_to_split_by, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test and train attributes defined 0.3.\n",
      "        Test size: 597\n",
      "        Train size: 1393\n"
     ]
    }
   ],
   "source": [
    "splitter_name = \"splitter\"\n",
    "\n",
    "splitter = Splitter(\n",
    "    name = splitter_name\n",
    "    , data_path = FE_DATA_PATH\n",
    "    , date_cols = []\n",
    "    , target_variable = 'loan_status'\n",
    "    , destination_directory = DATA_FOLDER\n",
    "    , dates_data_path = DATES_DATA_PATH\n",
    "    , column_to_split_by = 'finished_d'\n",
    "    , test_size = 0.3\n",
    "    , random_state = 47\n",
    ")\n",
    "\n",
    "splitter.execute()\n",
    "splitter.split_data_filtered(number_of_months=12)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object contains x_train, x_test, y_train and y_test, for the first 12 months, later we can try with more months bu just changing \"number_of_months\".\n",
    "\n",
    "# 2 Modelling first year of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, \n",
    "\n",
    "mlflow.set_experiment(\"first_year\")\n",
    "experiment = mlflow.get_experiment_by_name(\"first_year\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "run = client.create_run(experiment.experiment_id)\n",
    "with mlflow.start_run(run_id = run.info.run_id):\n",
    "    gbm = cb.CatBoostClassifier(**params)\n",
    "    gbm.fit(train_dataset, eval_set=val_dataset, early_stopping_rounds=50)\n",
    "    preds = gbm.predict_proba(test_dataset)\n",
    "    ap = average_precision_score(test_dataset.get_label(), preds[:, 1])\n",
    "    roc = roc_auc_score(test_dataset.get_label(), preds[:, 1])\n",
    "\n",
    "    mlflow.log_metric(\"Test ROC AUC\", roc)\n",
    "    mlflow.log_metric(\"Test PR AUC\", ap)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.catboost.log_model(gbm, \"catboost_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def random_grid_search(model, param_distributions, X_train, y_train, seed):\n",
    "    \"\"\"\n",
    "    Perform a random grid search using scikit-learn's RandomizedSearchCV class.\n",
    "\n",
    "    Parameters:\n",
    "    - model: a scikit-learn model object\n",
    "    - param_distributions: a dictionary containing hyperparameter names and distributions\n",
    "    - X_train: training input data\n",
    "    - y_train: training output data\n",
    "    - n_iter: number of parameter settings that are sampled\n",
    "    - cv: number of cross-validation folds\n",
    "\n",
    "    Returns:\n",
    "    - best_estimator: the best estimator found during the search\n",
    "    - best_params: the hyperparameters of the best estimator\n",
    "    \"\"\"\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "    # Create a RandomizedSearchCV object\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        model, param_distributions, cv=cv, scoring='recall', n_iter=10)\n",
    "\n",
    "    # Fit the RandomizedSearchCV object to the data\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and score\n",
    "    print(\"Best parameters: {}\".format(search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(search.best_score_))\n",
    "\n",
    "    # Get the best estimator and its parameters\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    return best_estimator, best_params\n",
    "\n",
    "def cross_val_train_predict(model, X_train, y_train, X_test, scoring_metric, seed=SEED):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=seed)\n",
    "    scores = cross_val_score(model, X_train, y_train,\n",
    "                             scoring=scoring_metric, cv=cv, n_jobs=-1)\n",
    "    print('Mean Recall in Train: %.3f (%.3f)' %\n",
    "          (np.mean(scores), np.std(scores)))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "import mlflow\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def run_experiment(model, params, splitter, experiment_name, model_name, seed=SEED):\n",
    "    # Set the experiment name and tracking URI\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.set_tracking_uri('http://localhost:5000')\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    \n",
    "    # Create a decision tree model\n",
    "    model = model(**params)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(splitter.X_train, splitter.y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(splitter.X_test)\n",
    "    \n",
    "    # Evaluate the model performance\n",
    "    roc_auc = roc_auc_score(splitter.y_test, y_pred)\n",
    "    pr_auc = average_precision_score(splitter.y_test, y_pred)\n",
    "    precision = precision_score(splitter.y_test, y_pred)\n",
    "    recall = recall_score(splitter.y_test, y_pred)\n",
    "    accuracy = accuracy_score(splitter.y_test, y_pred)\n",
    "    \n",
    "    # Log the evaluation metrics and model parameters in MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(params)\n",
    "        mlflow.log_metric('roc_auc', roc_auc)\n",
    "        mlflow.log_metric('pr_auc', pr_auc)\n",
    "        mlflow.log_metric('precision', precision)\n",
    "        mlflow.log_metric('recall', recall)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "        \n",
    "        if model_logged:\n",
    "            mlflow.sklearn.log_model(model, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/04/28 20:34:42 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def set_experiment(experiment_name):\n",
    "    # Set the experiment name and tracking URI\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.set_tracking_uri('http://localhost:5000')\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    run = client.create_run(experiment.experiment_id)\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(experiment_name, model_class, params, splitter, log_model=False):\n",
    "    set_experiment(experiment_name)\n",
    "\n",
    "    mlflow.sklearn.autolog(log_models=log_model)\n",
    "    \n",
    "    # Log the evaluation metrics and model parameters in MLflow\n",
    "    with mlflow.start_run():\n",
    "        model = model_class(**params)  # create a new instance of the model class\n",
    "        model.fit(splitter.X_train, splitter.y_train)\n",
    "        y_pred = model.predict(splitter.X_test)\n",
    "            \n",
    "run_experiment('test3'\n",
    "               , DecisionTreeClassifier\n",
    "               , {'max_depth': 5}\n",
    "               , splitter\n",
    "               )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
